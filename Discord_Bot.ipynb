{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKqbu6kQd4w/yh+24CwfeP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annikarichardson2024/Project-2/blob/main/Discord_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeQt3Wr4izv7",
        "outputId": "501d8a1c-6204-4df0-dcfc-10d995ebb422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MHya3mAjI2G",
        "outputId": "e9eec9d9-4666-46a1-f40a-090ad49f8c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install discord.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRrs4SngmvBF",
        "outputId": "aa9ab290-9168-452f-a98e-5dc7ed5b1b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting discord.py\n",
            "  Downloading discord.py-2.3.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4,>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from discord.py) (3.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<4,>=3.7.4->discord.py) (3.7)\n",
            "Installing collected packages: discord.py\n",
            "Successfully installed discord.py-2.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4iN-T2FiR5n"
      },
      "outputs": [],
      "source": [
        "from typing import Final\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from discord import Intents, Client, Message\n",
        "from random import choice, randint\n",
        "import openai\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "import requests\n",
        "import requests.exceptions\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "JskWYzcrqX3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyNaCl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_lsPl8q1f9Y",
        "outputId": "b1bb06ae-0a77-4d03-8672-dffcd348ca19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyNaCl\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from PyNaCl) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.1->PyNaCl) (2.22)\n",
            "Installing collected packages: PyNaCl\n",
            "Successfully installed PyNaCl-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = 'key'"
      ],
      "metadata": {
        "id": "4hsPOICii_Bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()\n",
        "TOKEN = os.getenv('token')\n",
        "print (TOKEN)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBJtUGYKiYt5",
        "outputId": "1341119f-4198-44df-a34c-3689ac5a872d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intents = Intents.default()\n",
        "intents.messages = True\n",
        "client = Client(intents=intents)"
      ],
      "metadata": {
        "id": "ohBk0uGWm6Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_openai(question):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": question}\n",
        "        ]\n",
        "    )\n",
        "    answer = response['choices'][0]['message']['content']\n",
        "    return answer"
      ],
      "metadata": {
        "id": "fAq4xk0lp1uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(user_input: str) -> str:\n",
        "    lowered: str = user_input.lower()\n",
        "\n",
        "    if lowered == '':\n",
        "        return 'Well, you are quiet'\n",
        "    elif 'hello' in lowered:\n",
        "        return 'Hello there! You need to code your AI Bot here'\n",
        "    elif 'roll dice' in lowered:\n",
        "        return f'You rolled a {randint(1, 6)}'\n",
        "    elif 'help' in lowered:\n",
        "        return f'you can say !data, !temp, or !pressure'\n",
        "    else:\n",
        "        return ask_openai(user_input)"
      ],
      "metadata": {
        "id": "dM75zQCcp9V8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Messaging\n",
        "async def send_message(message: Message,user_message: str) -> None:\n",
        "    if not user_message:\n",
        "        print('(Message was empty becuase intents were not enabled...prob)')\n",
        "        return\n",
        "\n",
        "#private messages response\n",
        "    if is_private := user_message[0] =='?':\n",
        "        user_message = user_message[1:]\n",
        "\n",
        "    try:\n",
        "        response: str= get_response(user_message)\n",
        "        await message.author.send(response) if is_private else await message.channel.send(response)\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "metadata": {
        "id": "7PKo8hRZqDNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#startup of the bot\n",
        "@client.event\n",
        "async def on_ready() -> None:\n",
        "    print(f'{client.user} is now running!')\n",
        "\n",
        "@client.event\n",
        "async def on_message(message: Message) -> None:\n",
        "    if message.author == client.user:\n",
        "        return\n",
        "\n",
        "    username: str= str(message.author)\n",
        "    user_message: str = message.content\n",
        "    channel: str = str(message.channel)\n",
        "\n",
        "    print(f'[{channel}] {username}: \"{user_message}\"')\n",
        "    await send_message(message, user_message)\n"
      ],
      "metadata": {
        "id": "Ge6Fk2c1qE9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Starting point\n",
        "\n",
        "def main():\n",
        "    client.run(token=TOKEN)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "qOA3Vz4rqGWx",
        "outputId": "131b9266-e0b9-4ffe-c6f2-c02130e8eddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "asyncio.run() cannot be called from a running event loop",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-871c75d25933>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-871c75d25933>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTOKEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/discord/client.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, token, reconnect, log_handler, log_formatter, log_level, root_logger)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# nothing to do here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m     34\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "1W9LwOeVV7yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# handling basic Q and A\n",
        "questions = ['Hello', 'How are you?','Goodbye', 'help']\n",
        "answers = ['Hey there!','Very well.','Goodbye!', 'what is your issue?']"
      ],
      "metadata": {
        "id": "ikXmYOkRW02I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(questions + answers)\n",
        "sequences_q = tokenizer.texts_to_sequences(questions)\n",
        "sequences_a = tokenizer.texts_to_sequences(answers)"
      ],
      "metadata": {
        "id": "Ou75s5ffXvAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = max(max(len(seq) for seq in sequences_q), max(len(seq) for seq in sequences_a))\n",
        "padded_q = tf.keras.preprocessing.sequence.pad_sequences(sequences_q, maxlen=max_length, padding='post')\n",
        "padded_a = tf.keras.preprocessing.sequence.pad_sequences(sequences_a, maxlen=max_length, padding='post')"
      ],
      "metadata": {
        "id": "YjUvdukFXz2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 2000\n",
        "units = 1000\n",
        "vocab_size = 5000"
      ],
      "metadata": {
        "id": "suHG4Pn2X1-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder model\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "encoder_embedding = Embedding(vocab_size, embedding_dim)(encoder_inputs)\n",
        "encoder_outputs, state_h, state_c = LSTM(units, return_state=True)(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# decoder model\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_embedding = Embedding(vocab_size, embedding_dim)(decoder_inputs)\n",
        "decoder_lstm = LSTM(units, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "decoder_dense = Dense(vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "g7b0xAERX39M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seq2seq model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# compiling the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "67kZ4-z5X6hO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input_data = np.zeros_like(padded_a)\n",
        "decoder_input_data[:, 0] = 1\n",
        "\n",
        "# Train  model\n",
        "num_epochs = 100\n",
        "model.fit([padded_q, decoder_input_data], np.expand_dims(padded_a, -1), batch_size=2, epochs=num_epochs)"
      ],
      "metadata": {
        "id": "y8QrthQdX8jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(input_text):\n",
        "    sequence = tokenizer.texts_to_sequences([input_text])\n",
        "    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=max_length, padding='post')\n",
        "    return padded_sequence\n",
        "\n",
        "def generate(input_sequence):\n",
        "    response_sequence = np.zeros((1, max_length))\n",
        "    response_sequence[0, 0] = 1\n",
        "    for i in range(1, max_length):\n",
        "        prediction = model.predict([input_sequence, response_sequence]).argmax(axis=2)\n",
        "        response_sequence[0, i] = prediction[0, i-1]\n",
        "        if prediction[0, i-1] == 2:\n",
        "            break\n",
        "    return response_sequence\n",
        "\n",
        "def sequence(sequence):\n",
        "    return ' '.join(tokenizer.index_word.get(i, '') for i in sequence if i > 2)"
      ],
      "metadata": {
        "id": "YUcPuoIbW-8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(input_text):\n",
        "    input_sequence = preprocess(input_text)\n",
        "    response_sequence = generate(input_sequence)\n",
        "    response_text = sequence(response_sequence[0])\n",
        "    return response_text"
      ],
      "metadata": {
        "id": "TzOlQHcUXI4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True: # function that adresses ending convo\n",
        "    question = input('You: ')\n",
        "    if question.lower() == 'i quit':\n",
        "        break\n",
        "    if question.lower() == 'goodbye':\n",
        "        break\n",
        "    if question.lower() == 'i am done':\n",
        "        break\n",
        "    response = chat(question)\n",
        "    print(f\"Chatbot: {response}\")"
      ],
      "metadata": {
        "id": "yms4iFKZV8Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling API calls"
      ],
      "metadata": {
        "id": "xboG6Xt3u2Vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pprint\n",
        "import requests\n",
        "import requests.exceptions\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "uCh8UF1Au18e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_api_response(url, response_type):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "\n",
        "    except requests.exceptions.HTTPError as errh:\n",
        "        return \"An Http Error occurred: \" + repr(errh)\n",
        "    except requests.exceptions.ConnectionError as errc:\n",
        "        return \"An Error Connecting to the API occurred: \" + repr(errc)\n",
        "    except requests.exceptions.Timeout as errt:\n",
        "        return \"A Timeout Error occurred: \" + repr(errt)\n",
        "    except requests.exceptions.RequestException as err:\n",
        "        return \"An Unknown Error occurred: \" + repr(err)\n",
        "\n",
        "    if response_type == 'json':\n",
        "        result = json.dumps(response.json(), sort_keys=True, indent=4)\n",
        "    elif response_type == 'dataframe':\n",
        "        result = pd.json_normalize(response.json())\n",
        "    else:\n",
        "        result = \"An unhandled error has occurred!\"\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "Ri7cSLSMvKv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this loads in an api\n",
        "\n",
        "url = \"https://restcountries.com/v3.1/name/del\"\n",
        "response_type = ['json', 'dataframe']\n",
        "df2 = get_api_response(url, response_type[1])\n",
        "df2.info()"
      ],
      "metadata": {
        "id": "s43SkS0LvUu3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}